server:
  port: 8081
spring:
  application:
    name: arcstorage
  datasource:
    url: jdbc:postgresql://localhost:5432/arcstorage
    driver-class-name: org.postgresql.Driver
    name: mainPool
    username: changeme
    password: changeme
  jpa:
    show-sql: false
    database-platform: org.hibernate.dialect.PostgreSQL9Dialect
    hibernate:
      ddl-auto: validate
      naming-strategy: org.hibernate.cfg.ImprovedNamingStrategy
      use-new-id-generator-mappings: true
  http:
    multipart:
      enabled: false
  jackson:
    serialization:
      write-dates-as-timestamps: false
  mail:
    host: smtp.gmail.com
    port: 465
    username: unknown
    password: unknown
    protocol: smtp
    properties.mail.smtp:
      auth: true
      starttls.enable: false
      ssl.trust: smtp.gmail.com
      ssl.enable: true
  liquibase:
    enabled: true
    changeLog: classpath:/dbchangelog.arcstorage.xml
mail:
  sender:
    email: --sender address--
    name: Archival Storage
  app:
    name: Archival Storage
    logo: logo.png
    link: http://arclib.inqool.cz
    url: http://arclib.inqool.cz
    path:
      tasks:
  enabled: true
arcstorage:
  threadPools:
    batchOps: 16 # threads for asynchronous batch operations (saveAip, saveXml, deleteAip etc.)
    scheduled: 2 # threads reserved for periodical jobs (e.g. reachability check)
  tmpFolder: tmp # folder to which uploaded files are written before sent to logical storages.. also used when downloading files etc.
  # tmpFolderUploadSizeLimit: 500000 # in MB, if tmp folder reach the limit, all multipart upload requests will fail, not value set means no limit
  connectionTimeout: 5000 # timeout for initial connection to remote logical storage, in milliseconds
  stateChangeTransactionTimeout: 5 # timeout of all DB transactions that changes the state of an archival object, in seconds
  synchronizationInitTimeout: 15 # timeout until which all processing objects should reach final state, otherwise the synchronization wont start, in seconds
  cleanUpAtApplicationStart: false # automatically clean up all processing and failed objects from storage
  backupDirPath: backup
  consistencyCheck:
    cron: "0 0 8 ? * 2"
    count: 10
  storageStateCheck:
    cron: "0 0 8 ? * 2"
  # credentials used by system when executing remote commands at logical storage over SSH
  ssh:
    authKey: --path to private key--
    userName: --username--
env: production
logging.file.path: ../logs


